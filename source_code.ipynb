{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7672e6e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation for y:\n",
      "Mean ROC AUC Score for h1n1_vaccine = 0.8415840484095816\n",
      "\n",
      "Evaluation for z:\n",
      "Mean ROC AUC Score for seasonal_vaccine = 0.8588153071611204\n",
      "\n",
      "Overall ROC AUC Score = 0.850199677785351\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.experimental import enable_iterative_imputer  # noqa\n",
    "from sklearn.impute import SimpleImputer, IterativeImputer\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Load the datasets\n",
    "X = pd.read_csv(\"training_set_features.csv\") # Load the training features\n",
    "y = pd.read_csv(\"training_set_labels.csv\") # Load the training labels \n",
    "z = pd.read_csv(\"training_set_labels.csv\") # Load the training labels (for another target variable)\n",
    "final = pd.read_csv(\"test_set_features.csv\") # Load the test features\n",
    "\n",
    "# Remove respondent_id, employment_industry, employment_occupation and health_insurance from X \n",
    "X = X.drop(['respondent_id', 'employment_industry', 'employment_occupation', 'health_insurance'], axis=1)\n",
    "\n",
    "# Remove respondent_id, seasonal_vaccine from y\n",
    "y = y.drop(['respondent_id', 'seasonal_vaccine'], axis=1)\n",
    "\n",
    "# Remove respondent_id, seasonal_vaccine from z \n",
    "z= z.drop(['respondent_id', 'h1n1_vaccine'], axis=1)\n",
    "\n",
    "# Extracting the respondent_id column from the final \n",
    "respondent_id = final['respondent_id']\n",
    "\n",
    "# Remove respondent_id, employment_industry, employment_occupation and health_insurance from final dataframe\n",
    "final = final.drop(['respondent_id', 'employment_industry', 'employment_occupation', 'health_insurance'], axis=1)\n",
    "\n",
    "# Define numerical and categorical features\n",
    "numerical_features = X.select_dtypes(include=['float64']).columns\n",
    "categorical_features = X.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Define numerical and categorical transformers\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('imputer', IterativeImputer(max_iter=12, tol=0.001, random_state=42)),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Combine numerical and categorical transformers using ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Define stratified k-fold cross-validator\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Define function to evaluate model\n",
    "def evaluate_model(X_data, y_data):\n",
    "    \n",
    "    # Compute scale_pos_weight based on the class distribution in the training data\n",
    "    scale_pos_weight = (len(y_data) - y_data.sum()) / y_data.sum()\n",
    "    \n",
    "    # Define the BaggingClassifier with XGBClassifier as the base estimator\n",
    "    model_xgb = XGBClassifier(n_estimators=100, scale_pos_weight=scale_pos_weight, max_depth=7,\n",
    "                              min_child_weight=15, eta=0.07, reg_lambda=0.15,\n",
    "                              objective=\"binary:logistic\", eval_metric='auc', random_state=42)\n",
    "    model_bagging = BaggingClassifier(estimator=model_xgb, n_estimators=50, random_state=42, \n",
    "                                      max_samples=0.8,max_features=0.9, bootstrap=True)\n",
    "\n",
    "    roc_auc_scores = []\n",
    " \n",
    "    # Perform stratified k-fold taining and testing\n",
    "    for train_index, test_index in skf.split(X_data, y_data):\n",
    "        X_train_skf, X_test_skf = X_data[train_index], X_data[test_index]\n",
    "        y_train_skf, y_test_skf = y_data[train_index], y_data[test_index]\n",
    "\n",
    "        # Fit the model\n",
    "        model_bagging.fit(X_train_skf, y_train_skf)\n",
    "\n",
    "        # Predict on the test set\n",
    "        y_pred_skf = model_bagging.predict(X_test_skf)\n",
    "\n",
    "        # Evaluate the model\n",
    "        y_pred_proba = model_bagging.predict_proba(X_test_skf)[:, 1]  # Probability of positive class\n",
    "        roc_auc = roc_auc_score(y_test_skf, y_pred_proba, average=\"macro\")\n",
    "        roc_auc_scores.append(roc_auc)\n",
    "        \n",
    "    # Calculate mean roc_auc scores across all fold\n",
    "    mean_roc_auc = sum(roc_auc_scores) / len(roc_auc_scores)\n",
    "    \n",
    "    return model_bagging, mean_roc_auc\n",
    "\n",
    "# Preprocess X\n",
    "X_processed = preprocessor.fit_transform(X)\n",
    "\n",
    "# Evaluate model for y\n",
    "print(\"Evaluation for y:\")\n",
    "model_y, roc_auc_y = evaluate_model(X_processed, y.values.ravel())\n",
    "print(\"Mean ROC AUC Score for h1n1_vaccine =\", roc_auc_y)\n",
    "\n",
    "# Evaluate model for z\n",
    "print(\"\\nEvaluation for z:\")\n",
    "model_z, roc_auc_z = evaluate_model(X_processed, z.values.ravel())\n",
    "print(\"Mean ROC AUC Score for seasonal_vaccine =\", roc_auc_z)\n",
    "\n",
    "# Calculate final mean roc_auc score for both y and z\n",
    "final_mean_roc_auc = (roc_auc_y + roc_auc_z) / 2\n",
    "print(\"\\nOverall ROC AUC Score =\", final_mean_roc_auc)\n",
    "\n",
    "# Transform final\n",
    "final_processed = preprocessor.transform(final)\n",
    "\n",
    "# Predict probabilities for final \n",
    "h1n1_vaccine_probs = model_y.predict_proba(final_processed)[:, 1]\n",
    "seasonal_vaccine_probs = model_z.predict_proba(final_processed)[:, 1]\n",
    "\n",
    "# Round the probabilities to one decimal place\n",
    "h1n1_vaccine = np.round(h1n1_vaccine_probs, 1)\n",
    "seasonal_vaccine = np.round(seasonal_vaccine_probs, 1)\n",
    "\n",
    "# Create DataFrame for predictions\n",
    "predictions_df = pd.DataFrame({\n",
    "    'respondent_id': respondent_id,\n",
    "    'h1n1_vaccine': h1n1_vaccine,\n",
    "    'seasonal_vaccine': seasonal_vaccine\n",
    "})\n",
    "\n",
    "# Save results to CSV file\n",
    "predictions_df.to_csv(\"results.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5772cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
